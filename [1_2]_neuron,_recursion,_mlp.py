# -*- coding: utf-8 -*-
"""[1_2] neuron, recursion, mlp

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VBszFyrFS0RpQkys93jtqdQg0oRvQD3W
"""

class Tensor:
    def __init__(self, data):
        self.data = data

    def __add__(self, other):
        other = other if isinstance(other, Tensor) else Tensor(other)
        out = Tensor(self.data + other.data)
        return out

    def __mul__(self, other):
        other = other if isinstance(other, Tensor) else Tensor(other)
        out = Tensor(self.data * other.data)
        return out

    def __radd__(self, other):
        return self + other

    def __rmul__(self, other):
        return self * other

    def __repr__(self):
        return f"Tensor with {self.data}"

"""# `self.prev`"""

import numpy as np

class Tensor:

    def __init__(self, data, prev=()):
        self.data = data
        self.prev = prev

    def __add__(self, other):
        other = other if isinstance(other, Tensor) else Tensor(other)
        out = Tensor(self.data + other.data, prev=(self, other))
        return out

    def __mul__(self, other):
        other = other if isinstance(other, Tensor) else Tensor(other)
        out = Tensor(self.data * other.data, prev=(self, other))
        return out

    def __radd__(self, other):
        return self + other

    def __rmul__(self, other):
        return self * other

    def relu(self):
        return Tensor(np.maximum(self.data, 0), prev=(self,))

    def __repr__(self):
        return f"Tensor(data={self.data}, prev={self.prev})"

Tensor(1.0) + Tensor(2.0)

(Tensor(1.0) + Tensor(2.0)) * Tensor(5.0)

a = Tensor(1.0)
b = Tensor(2.0)
c = Tensor(-5.0)

((a + b) * c).relu()

"""https://alexlenail.me/NN-SVG/index.html

# Neuron

$$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2$$


$$y = w_1 x_1 + w_2 x_2 + b$$
"""

class Neuron:

    def __init__(self, nin):
        self.w = [Tensor(np.random.uniform(-1,1)) for _ in range(nin)]
        self.b = Tensor(np.random.uniform(-1,1))

    def __call__(self, x):
        act = sum([wi * xi for wi, xi in zip(self.w, x)]) + self.b
        out = act.relu()
        return out

n = Neuron(3)
n([1,2,3])

class Neuron:

    def __init__(self, nin):
        self.w = [Tensor(np.random.uniform(-1,1)) for _ in range(nin)]
        self.b = Tensor(np.random.uniform(-1,1))

    def __call__(self, x):
        #act = sum([wi * xi for wi, xi in zip(self.w, x)]) + self.b
        act = sum([wi * xi for wi, xi in zip(self.w, x)], self.b)
        out = act.relu()
        return out

np.random.seed(123)
Neuron(3)

x = [2.3, 3.4, 4.5]

n = Neuron(3)
n(x)

"""n! = n * (n-1) * ... * 1

n! = n * (n-1)!
"""

def factorial(n):

    if n == 0:
        return 1

    else:
        return n * factorial(n - 1)

# Test the function
print(factorial(5))  # Output: 120

def print_tensor_tree(tensor, level=0):
    indent = "    " * level
    print(f"{indent}Tensor(data={tensor.data})")
    for prev_tensor in tensor.prev:
        print_tensor_tree(prev_tensor, level + 1)

"""# Tree

[ChatGPT] What is the structure of recursion in Python?
"""

n(x)

def traverse_tensor(tensor, depth=0):
    # Print the current tensor's data with indentation based on the recursion depth
    print("  " * depth + f"Tensor(data={tensor.data:.2f})")
    # Recursively traverse the previous tensors
    for prev_tensor in tensor.prev:
        traverse_tensor(prev_tensor, depth + 1)

traverse_tensor(n(x))

from graphviz import Digraph

# Function to add nodes and edges to the Graphviz graph from the tensor structure
def add_nodes_edges_graphviz(graph, tensor, parent_id=None, current_id=0):
    node_id = str(current_id)
    graph.node(node_id, label=f"{tensor.data:.2f}")
    if parent_id is not None:
        graph.edge(parent_id, node_id)
    next_id = current_id + 1
    for prev_tensor in tensor.prev:
        graph, next_id = add_nodes_edges_graphviz(graph, prev_tensor, node_id, next_id)
    return graph, next_id

# Function to plot the tensor tree and display it
def plot_tensor_tree(tensor):
    dot = Digraph()
    dot, _ = add_nodes_edges_graphviz(dot, tensor)
    return dot

plot_tensor_tree(n(x))

"""# Neural Networks"""

class Layer:

    def __init__(self, nin, nout):
        self.neurons = [Neuron(nin) for _ in range(nout)]

    def __call__(self, x):
        out = [n(x) for n in self.neurons]
        return out
        #return out[0] if len(out) == 1 else out

Layer(3, 4)(x)

"""

```
MLP(3, [4, 2, 1])

Layer(3,4)
Layer(4,2)
Layer(2,1)

Layer(nin, nout)

Neuron(nin)

[Neuron(3), Neuron(3), Neuron(3), Neuron(3)]
[Neuron(4), Neuron(4)]
[Neuron(2)]
```

"""

MLP(3, [4, 2, 1])

class MLP:

    def __init__(self, nin, nouts):
        sz = [nin] + nouts
        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]

    def __call__(self, x):
        for layer in self.layers:
            x = layer(x)
        return x

n = MLP(3,[4,2,1])

n(x)

traverse_tensor(n(x))

plot_tensor_tree(n(x))

