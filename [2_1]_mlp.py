# -*- coding: utf-8 -*-
"""[2_1] mlp

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13JuU8gPhxbYfNwQnHeF9tRbYy_dWqE4P
"""

import numpy as np

class Tensor:

    def __init__(self, data, prev=()):
        self.data = data
        self.prev = prev

    def __add__(self, other):
        other = other if isinstance(other, Tensor) else Tensor(other)
        out = Tensor(self.data + other.data, prev=(self, other))
        return out

    def __mul__(self, other):
        other = other if isinstance(other, Tensor) else Tensor(other)
        out = Tensor(self.data * other.data, prev=(self, other))
        return out

    def __radd__(self, other):
        return self + other

    def __rmul__(self, other):
        return self * other

    def relu(self):
        return Tensor(np.maximum(self.data, 0), prev=(self,))

    def __repr__(self):
        #return f"Tensor(data={self.data}, prev={self.prev})"
        return f"Tensor(data={self.data})"

class Neuron:

    def __init__(self, nin):
        self.w = [Tensor(np.random.uniform(-1,1)) for _ in range(nin)]
        self.b = Tensor(np.random.uniform(-1,1))

    def __call__(self, x):
        act = sum([wi * xi for wi, xi in zip(self.w, x)], self.b)
        out = act.relu()
        return out

def traverse_tensor(tensor, depth=0):
    # Print the current tensor's data with indentation based on the recursion depth
    print("  " * depth + f"Tensor(data={tensor.data:.2f})")
    # Recursively traverse the previous tensors
    for prev_tensor in tensor.prev:
        traverse_tensor(prev_tensor, depth + 1)

from graphviz import Digraph

# Function to add nodes and edges to the Graphviz graph from the tensor structure
def add_nodes_edges_graphviz(graph, tensor, parent_id=None, current_id=0):
    node_id = str(current_id)
    graph.node(node_id, label=f"{tensor.data:.2f}")
    if parent_id is not None:
        graph.edge(parent_id, node_id)
    next_id = current_id + 1
    for prev_tensor in tensor.prev:
        graph, next_id = add_nodes_edges_graphviz(graph, prev_tensor, node_id, next_id)
    return graph, next_id

# Function to plot the tensor tree and display it
def plot_tensor_tree(tensor):
    dot = Digraph()
    dot, _ = add_nodes_edges_graphviz(dot, tensor)
    return dot

np.random.seed(123)
Neuron(3)

x = [2.3, 3.4, 4.5]

n = Neuron(3)
n(x)

traverse_tensor(n(x))

plot_tensor_tree(n(x))

"""# Neural Networks"""

class Layer:

    def __init__(self, nin, nout):
        self.neurons = [Neuron(nin) for _ in range(nout)]

    def __call__(self, x):
        out = [n(x) for n in self.neurons]
        # return out
        return out[0] if len(out) == 1 else out

L1 = Layer(3, 4)

L1

L1(x)

L2 = Layer(4, 2)
L2(L1(x))

L3 = Layer(2, 1)
L3(L2(L1(x)))

MLP(3, [4, 2, 1])

class MLP:

    def __init__(self, nin, nouts):
        sz = [nin] + nouts
        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]

    def __call__(self, x):
        for layer in self.layers:
            x = layer(x)
        return x

n = MLP(3,[4,2,1])

n(x)

traverse_tensor(n(x))

plot_tensor_tree(n(x))



"""# Differentiation vs. Gradient"""

def fn(x, y, z):
    return x**2 + 3*y + x*z

fn(1,2,3)

fn(2,3,4)

h = 0.001

(fn(2+h,3,4) - fn(2,3,4))/h

(fn(2,3+h,4) - fn(2,3,4))/h

(fn(2,3,4+h) - fn(2,3,4))/h

